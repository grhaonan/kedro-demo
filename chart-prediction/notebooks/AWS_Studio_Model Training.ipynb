{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95ba3025-1837-4f6f-9ab9-cc03a8733ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install datasets\n",
    "#!pip install transformers\n",
    "#!pip install evaluate\n",
    "#!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d6ba39a-9505-4dd9-8786-cbf3b0acc8aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import TrainingArguments\n",
    "import evaluate\n",
    "from datasets import load_dataset\n",
    "from transformers import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a60a264b-5767-4746-9dcf-7bc001d39513",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check GPU\n",
    "import torch\n",
    "torch.cuda.is_available()\n",
    "#torch.cuda.current_device()\n",
    "#torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d40d65-bdd9-4c4e-8dd3-93eea2f64a73",
   "metadata": {},
   "source": [
    "## System setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "22987fd7-4655-48ea-a92b-5a106097584a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# seed number\n",
    "random_state = 42\n",
    "\n",
    "# model to be used, from hugging face\n",
    "model_name = \"bert-base-cased\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd865ec-504f-4a59-be6c-45f60fdd2e3d",
   "metadata": {},
   "source": [
    "## Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6b75f31c-e445-4231-bd23-e4b92b8ce007",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#pandas loading file\n",
    "raw_data_df = pd.read_csv('./all_years_10000_per_class.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fa0b71a8-3b7d-4167-8e96-aac4390577a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The class should be in balance\n",
    "#raw_data_df.groupby(['selected_chart_code']).size().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d3fbfabd-6a04-4c82-b98b-5568480eb65f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#raw_data_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "89a423ab-3f1c-481c-aa48-6b0e83a9b36b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#building target labels\n",
    "chart_code_to_target_label = pd.DataFrame(sorted(raw_data_df['selected_chart_code'].unique()))\n",
    "# rename this column from 0 to a presentive name\n",
    "chart_code_to_target_label.columns = ['selected_chart_code']\n",
    "# use index as the label\n",
    "chart_code_to_target_label['label'] = chart_code_to_target_label.index\n",
    "# adding label to raw data\n",
    "processed_data_df = pd.merge(raw_data_df, chart_code_to_target_label, how = \"inner\", on=['selected_chart_code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "77cf08c2-45c7-4e3d-91ae-41b4226bd864",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# viz chart code to target label relationship\n",
    "# chart_code_to_target_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "25bc2452-993f-4edc-8a45-3b7d9cc7aa31",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# viz processed data\n",
    "# processed_data_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971370a0-7206-43f1-8502-177a62efd215",
   "metadata": {},
   "source": [
    "### Training, validation and test data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3775b816-5cfa-4bdc-a83c-3d0185c104a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 80% training and 20% test with stratify sampling enable to ensure balance\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    processed_data_df.loc[:, processed_data_df.columns != \"label\"],\n",
    "    processed_data_df['label'], \n",
    "    test_size = 0.2, \n",
    "    stratify=processed_data_df['label'],\n",
    "    random_state=random_state\n",
    "    )\n",
    "\n",
    "# As train_test_split doesn't support the split of validation, we will further split it from the training set\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    test_size=0.1,\n",
    "    stratify=y_train,\n",
    "    random_state=random_state\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a13ccc43-9c10-43db-b5e9-4f462cdd4ad7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# All classes should in balance\n",
    "# X_train.groupby(['selected_chart_code']).size().plot(kind='bar')\n",
    "\n",
    "# All classes should in balance\n",
    "# X_test.groupby(['selected_chart_code']).size().plot(kind='bar')\n",
    "\n",
    "# All classes should in balance\n",
    "# X_val.groupby(['selected_chart_code']).size().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96a67b9-e2a3-46f6-9b3c-3307506bdbb8",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83465af-49f4-48c8-92c1-915c492bf601",
   "metadata": {},
   "source": [
    "### Input for tokenisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "215c7b3d-c023-4d21-8fb9-bf4ef7429874",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Initiate\n",
    "train_set = pd.DataFrame()\n",
    "test_set = pd.DataFrame()\n",
    "val_set = pd.DataFrame()\n",
    "cols = ['transactiondate','etamount','transdescription']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e3228c5c-53f1-471a-967d-ccb757b78c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concate a few columns to form a new text descritpion as the training input\n",
    "train_set['text'] = X_train[cols].apply(lambda row: '_'.join(row.values.astype(str)), axis=1)\n",
    "train_set['label'] = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8fb3e4d6-d76e-467a-876b-b2a057e5b7f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Same feature engineering for test\n",
    "test_set['text'] = X_test[cols].apply(lambda row: '_'.join(row.values.astype(str)), axis=1)\n",
    "test_set['label'] = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "22de17ba-187e-439e-92f6-e2cb936cb628",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Same feature engineering for validateion se\n",
    "val_set['text'] = X_val[cols].apply(lambda row: '_'.join(row.values.astype(str)), axis=1)\n",
    "val_set['label'] = y_val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b29f18ff-b74b-42c8-8bce-76e3760c3ea8",
   "metadata": {},
   "source": [
    "### Converting to Huggingface dataset format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ea8c9ec3-645b-4543-8184-9c2a81a21a9d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Need to convert to Huggingface Dataset format which is reuqired for later tonisation process\n",
    "train_hf_dataset = Dataset.from_pandas(train_set)\n",
    "test_hf_dataset = Dataset.from_pandas(test_set)\n",
    "val_hf_dataset = Dataset.from_pandas(val_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e367d29-7c9b-4ebc-b737-31f635ea67b4",
   "metadata": {},
   "source": [
    "### Tokenisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343ab55f-102d-4a24-8e70-991fa63c25f5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a93fa682d0b4c3b8bd6a79b6ec516d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/555 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac828dcaa4614a90b06376fe0532a602",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/154 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokeniser = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "def tokenise_function(examples):\n",
    "    return tokeniser(examples[\"text\"], padding= \"max_length\",truncation=True, return_tensors = \"pt\")\n",
    "\n",
    "# tokenising each dataset\n",
    "tokenised_train_set = train_hf_dataset.map(tokenise_function, batched=True)\n",
    "tokenised_test_set = test_hf_dataset.map(tokenise_function, batched=True)\n",
    "tokenised_val_set = val_hf_dataset.map(tokenise_function, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69a845d-2411-4058-88a6-078583931cb4",
   "metadata": {},
   "source": [
    "## Define Trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5273cf5-a1c8-4f1e-8af4-76d07046ab36",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a1303d0-7a35-4259-8b3d-a8f11ecb77e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# defining metrics\n",
    "\n",
    "def compute_metrics (eval_pred):\n",
    "    metric = evaluate.load(\"f1\")\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis = -1)\n",
    "    return metric.compute(predictions=preds, references = labels, average = \"micro\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40fa3a9c-e115-4a08-9253-1ed2c1135f7d",
   "metadata": {},
   "source": [
    "### Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e268b95-901c-4918-88b1-9859ed8baa0c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_set' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-9d501fe3093c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# define model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnum_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoModelForSequenceClassification\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# training arguments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_set' is not defined"
     ]
    }
   ],
   "source": [
    "# define model\n",
    "num_labels = len(train_set['label'].unique())\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=num_labels)\n",
    "\n",
    "# training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir = \"test_trainer\", \n",
    "    evaluation_strategy = \"steps\",\n",
    "    logging_steps = 3000\n",
    "\n",
    ")\n",
    "\n",
    "# trainer\n",
    "trainer =  Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenised_train_set,\n",
    "    eval_dataset=tokenised_val_set,\n",
    "    compute_metrics = compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d481bd-b550-4cf5-bcec-27f7ad64c62d",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30980af-82d6-4833-b404-06c874975dd1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:ap-southeast-2:452832661640:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
